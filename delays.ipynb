{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Building a classification model using XGBoost in Python\n"
      ],
      "metadata": {
        "id": "05x_Vx8_pyaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction"
      ],
      "metadata": {
        "id": "7mtkRjgMqMG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Breakdown of XGBoost"
      ],
      "metadata": {
        "id": "HuFmja4SqRgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost, or Extreme Gradient Boosting, is a high-performing, regularized form of gradient boosting. For this project, I'm going to assume that you have a basic understanding of tree-based models and the gradient boosting algorithm. Like gradient boosting, XGBoost trains tree models sequentially and learns and improves at each step based on the results of the last step. Gradient boosting does this by taking the derivative, or gradient, of the loss function. Using a set learning rate and step size, this gradient is used to update parameters until they converge to an optimal solution. \n",
        "\n",
        "XGBoost builds on this gradient algorithm by taking the second derivative of the loss function and by adding L1/L2 regularization to the model to improve performance. The model is represented mathematically as follows:\n",
        "\n",
        "\n",
        "$$obj(\\theta) = L(\\theta) + Î©(\\theta)$$ where $L$ represents the loss function and $\\Omega$ represents the regularization term. \n",
        "\n",
        "XGBoost also takes advantage of parallel/distriubuted computing, which allows for incredibly fast performance when training on large datasets."
      ],
      "metadata": {
        "id": "2R6v3PdZrrT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running XGBoost in Python"
      ],
      "metadata": {
        "id": "IXRx4IjMeft4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost models can be easily implemented using the `xgboost` library, with installation instructions found at (https://xgboost.readthedocs.io/en/stable/install.html).\n",
        "\n",
        "Like all machine learning techniques, some preprocessing steps are needed to make sure the model runs well.\n",
        "\n",
        "In order to practice, we will be taking a look at a subset of data that was compiled from the Bureau of Trans- portation statistics and National Centers for Environmental Information (NOAA) that contains detailed airline, weather, airport and employment information. The goal is to predict whether or not a flight will be delayed by more than 15 minutes (DEP DEL15)."
      ],
      "metadata": {
        "id": "T09O3JuNejfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Data"
      ],
      "metadata": {
        "id": "951QqQyofi7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will be coding this up in google colab in order to take advantage of their free GPU's for training the model later. Lets start by importing packages, and importing data. In addition to the xgboost library, we will be using os, pandas, and numpy to assist in computing; sklearn for data preprocessing and model evaluation; and hyperopt for hyperparameter tuning."
      ],
      "metadata": {
        "id": "mMIWwXwIf2lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval"
      ],
      "metadata": {
        "id": "x5x_MlLDgHUf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting filepath to read data\n",
        "os.chdir('/content/drive/MyDrive/project2')"
      ],
      "metadata": {
        "id": "QYbt0fKkfnho"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "df = pd.read_csv('train_data.csv.zip')"
      ],
      "metadata": {
        "id": "SQ9LvGcOgWMC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore data"
      ],
      "metadata": {
        "id": "cQ1noJ_-hjxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "ZhALsDkggZwy",
        "outputId": "a7a7078a-7760-422f-8efb-746b662446c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MONTH  DAY_OF_WEEK  DEP_DEL15 DEP_TIME_BLK  DISTANCE_GROUP  SEGMENT_NUMBER  \\\n",
              "0      3            4          0    2200-2259               2               8   \n",
              "1      2            1          0    2000-2059               2               6   \n",
              "2      9            1          1    1800-1859               3               8   \n",
              "3      5            3          0    1600-1659               3               3   \n",
              "4      6            7          0    1900-1959               2               1   \n",
              "\n",
              "   CONCURRENT_FLIGHTS  NUMBER_OF_SEATS                  CARRIER_NAME  \\\n",
              "0                  21               90                   Comair Inc.   \n",
              "1                  44              180          Delta Air Lines Inc.   \n",
              "2                  92               50  American Eagle Airlines Inc.   \n",
              "3                  72              129          Delta Air Lines Inc.   \n",
              "4                  56              173         United Air Lines Inc.   \n",
              "\n",
              "   AIRPORT_FLIGHTS_MONTH  ...  PLANE_AGE                  DEPARTING_AIRPORT  \\\n",
              "0                  11965  ...          5  Ronald Reagan Washington National   \n",
              "1                  10714  ...          6  Minneapolis-St Paul International   \n",
              "2                  28583  ...         21       Chicago O'Hare International   \n",
              "3                  34238  ...         11                  Atlanta Municipal   \n",
              "4                  28904  ...          6       Chicago O'Hare International   \n",
              "\n",
              "   LATITUDE  LONGITUDE            PREVIOUS_AIRPORT  PRCP  SNOW SNWD  TMAX  \\\n",
              "0    38.852    -77.037       Memphis International  0.00   0.0  0.0  64.0   \n",
              "1    44.886    -93.218     Stapleton International  0.01   0.0  0.0  81.0   \n",
              "2    41.978    -87.906         Rochester Municipal  0.00   0.0  0.0  74.0   \n",
              "3    33.641    -84.427  Jacksonville International  0.00   0.0  0.0  84.0   \n",
              "4    41.978    -87.906                        NONE  0.38   0.0  0.0  81.0   \n",
              "\n",
              "    AWND  \n",
              "0   8.50  \n",
              "1   6.93  \n",
              "2   7.83  \n",
              "3   6.71  \n",
              "4  10.29  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2090070-d1c4-4469-80c6-4edaf804ddd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>DEP_DEL15</th>\n",
              "      <th>DEP_TIME_BLK</th>\n",
              "      <th>DISTANCE_GROUP</th>\n",
              "      <th>SEGMENT_NUMBER</th>\n",
              "      <th>CONCURRENT_FLIGHTS</th>\n",
              "      <th>NUMBER_OF_SEATS</th>\n",
              "      <th>CARRIER_NAME</th>\n",
              "      <th>AIRPORT_FLIGHTS_MONTH</th>\n",
              "      <th>...</th>\n",
              "      <th>PLANE_AGE</th>\n",
              "      <th>DEPARTING_AIRPORT</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>PREVIOUS_AIRPORT</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>AWND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2200-2259</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>90</td>\n",
              "      <td>Comair Inc.</td>\n",
              "      <td>11965</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Ronald Reagan Washington National</td>\n",
              "      <td>38.852</td>\n",
              "      <td>-77.037</td>\n",
              "      <td>Memphis International</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>8.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2000-2059</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>44</td>\n",
              "      <td>180</td>\n",
              "      <td>Delta Air Lines Inc.</td>\n",
              "      <td>10714</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Minneapolis-St Paul International</td>\n",
              "      <td>44.886</td>\n",
              "      <td>-93.218</td>\n",
              "      <td>Stapleton International</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>6.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1800-1859</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>92</td>\n",
              "      <td>50</td>\n",
              "      <td>American Eagle Airlines Inc.</td>\n",
              "      <td>28583</td>\n",
              "      <td>...</td>\n",
              "      <td>21</td>\n",
              "      <td>Chicago O'Hare International</td>\n",
              "      <td>41.978</td>\n",
              "      <td>-87.906</td>\n",
              "      <td>Rochester Municipal</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>7.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1600-1659</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>72</td>\n",
              "      <td>129</td>\n",
              "      <td>Delta Air Lines Inc.</td>\n",
              "      <td>34238</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>Atlanta Municipal</td>\n",
              "      <td>33.641</td>\n",
              "      <td>-84.427</td>\n",
              "      <td>Jacksonville International</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>6.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1900-1959</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>173</td>\n",
              "      <td>United Air Lines Inc.</td>\n",
              "      <td>28904</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Chicago O'Hare International</td>\n",
              "      <td>41.978</td>\n",
              "      <td>-87.906</td>\n",
              "      <td>NONE</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>10.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2090070-d1c4-4469-80c6-4edaf804ddd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2090070-d1c4-4469-80c6-4edaf804ddd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2090070-d1c4-4469-80c6-4edaf804ddd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SCfwbO4hoBL",
        "outputId": "1418fc24-7022-4f2c-dbc1-f2d948a24e0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1266241 entries, 0 to 1266240\n",
            "Data columns (total 26 columns):\n",
            " #   Column                         Non-Null Count    Dtype  \n",
            "---  ------                         --------------    -----  \n",
            " 0   MONTH                          1266241 non-null  int64  \n",
            " 1   DAY_OF_WEEK                    1266241 non-null  int64  \n",
            " 2   DEP_DEL15                      1266241 non-null  int64  \n",
            " 3   DEP_TIME_BLK                   1266241 non-null  object \n",
            " 4   DISTANCE_GROUP                 1266241 non-null  int64  \n",
            " 5   SEGMENT_NUMBER                 1266241 non-null  int64  \n",
            " 6   CONCURRENT_FLIGHTS             1266241 non-null  int64  \n",
            " 7   NUMBER_OF_SEATS                1266241 non-null  int64  \n",
            " 8   CARRIER_NAME                   1266241 non-null  object \n",
            " 9   AIRPORT_FLIGHTS_MONTH          1266241 non-null  int64  \n",
            " 10  AIRLINE_FLIGHTS_MONTH          1266241 non-null  int64  \n",
            " 11  AIRLINE_AIRPORT_FLIGHTS_MONTH  1266241 non-null  int64  \n",
            " 12  AVG_MONTHLY_PASS_AIRPORT       1266241 non-null  int64  \n",
            " 13  AVG_MONTHLY_PASS_AIRLINE       1266241 non-null  int64  \n",
            " 14  FLT_ATTENDANTS_PER_PASS        1266241 non-null  float64\n",
            " 15  GROUND_SERV_PER_PASS           1266241 non-null  float64\n",
            " 16  PLANE_AGE                      1266241 non-null  int64  \n",
            " 17  DEPARTING_AIRPORT              1266241 non-null  object \n",
            " 18  LATITUDE                       1266241 non-null  float64\n",
            " 19  LONGITUDE                      1266241 non-null  float64\n",
            " 20  PREVIOUS_AIRPORT               1266241 non-null  object \n",
            " 21  PRCP                           1266241 non-null  float64\n",
            " 22  SNOW                           1266241 non-null  float64\n",
            " 23  SNWD                           1266241 non-null  float64\n",
            " 24  TMAX                           1266241 non-null  float64\n",
            " 25  AWND                           1266241 non-null  float64\n",
            "dtypes: float64(9), int64(13), object(4)\n",
            "memory usage: 251.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data preprocessing"
      ],
      "metadata": {
        "id": "E4R7oon-h2NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After taking a quick look at our data, it's now time to do some preprocessing. I'm going to define a function with all of the preprocessing steps and then go over some items specifically."
      ],
      "metadata": {
        "id": "jl-oAHtah4FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function definitions and train test split\n",
        "def data_processing(data):\n",
        "  # target\n",
        "  y = data['DEP_DEL15']\n",
        "  # features\n",
        "  X = data.drop(['DEP_DEL15','PREVIOUS_AIRPORT'], axis=1)\n",
        "  # setting some discrete numeric features as categorical\n",
        "  X[['MONTH', 'DAY_OF_WEEK', 'DISTANCE_GROUP']] = X[['MONTH', 'DAY_OF_WEEK', 'DISTANCE_GROUP']].astype(object)\n",
        "  # defining numeric features and processor\n",
        "  numeric = X.select_dtypes(exclude='object').columns\n",
        "  numeric_processor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "  ])\n",
        "  # defining categorical features and processor\n",
        "  cat = X.select_dtypes(include='object').columns\n",
        "  categorical_processor = Pipeline([\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "  # defining complete preprocessor\n",
        "  preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_processor, numeric),\n",
        "    ('cat', categorical_processor, cat)\n",
        "  ])\n",
        "  # making train test split and fitting preprocessor\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.25, random_state=909)\n",
        "  X_train = preprocessor.fit_transform(X_train)\n",
        "  X_test = preprocessor.transform(X_test)\n",
        "  feature_names = preprocessor.get_feature_names_out(X.columns)\n",
        "  \n",
        "\n",
        "  return X_train, X_test, y_train, y_test, feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test, feature_names = data_processing(df)\n"
      ],
      "metadata": {
        "id": "wDOyMxDNiOD4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining target and feature variables"
      ],
      "metadata": {
        "id": "62PbYWaI22P_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm going to go over a few things just do we make sure that we all understand what's going on. First, we want to split our target and feature variables up:\n",
        "```\n",
        "y = data['DEP_DEL15']\n",
        "X = data.drop(['DEP_DEL15','PREVIOUS_AIRPORT'], axis=1)\n",
        "X[['MONTH', 'DAY_OF_WEEK', 'DISTANCE_GROUP']] = X[['MONTH', 'DAY_OF_WEEK', 'DISTANCE_GROUP']].astype(object)\n",
        "```\n",
        "Notice that in addition to dropping our target from the features, I've also dropped the PREVIOUS_AIRPORT field as well. The LATITUDE and LONGITUDE variables provide the location of the previous airport, so I felt that this would be redundant information. There were also a few discrete features that are better represented as categorical data, so that change was made as well."
      ],
      "metadata": {
        "id": "Zabdikts0UdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating preprocessing pipelines"
      ],
      "metadata": {
        "id": "Q_hqWIU82-fG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the target and features are in their own space. It's time to define some preprocessing pipelines. The data that we're working with has both categorical and numeric features, so it's easiest to create two seperate processors for both types, and then combine with a column transformer as follows:\n",
        "```\n",
        "numeric = X.select_dtypes(exclude='object').columns\n",
        "numeric_processor = Pipeline([\n",
        "  ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat = X.select_dtypes(include='object').columns\n",
        "categorical_processor = Pipeline([\n",
        "  ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "  ('num', numeric_processor, numeric),\n",
        "  ('cat', categorical_processor, cat)\n",
        "])\n",
        "```\n",
        "In order for the column transformer to work, the indices of the features need to be passed, so those need to be defined as they are above in the numeric and cat variables. For the numeric features, the only thing that we will do is standardize the variables. The categorical features will be encoded using one hot encoding. These two processors can be combined into a single processor using the column transformer."
      ],
      "metadata": {
        "id": "RPYBjzYS3ECB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting data for training and testing\n",
        "The next step is to randomly split up the data for training and then testing the model. It's easiest to do this with the `train_test_split` function from the `sklearn` library: \n",
        "```\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.25 random_state=909)\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "feature_names = preprocessor.get_feature_names_out(X.columns)\n",
        "```\n",
        "After splitting up the data, push it through the preprocessor in order to apply those transformations and put the data in a final state for modeling. It's also useful to save the feature names in case you need them later.\n",
        "\n",
        "At the end of the function, we can return all of the things that we need:\n",
        "```\n",
        "return X_train, X_test, y_train, y_test, feature_names\n",
        "```\n",
        "Now we can just call the function and input the data to get everything ready to go:\n",
        "```\n",
        "X_train, X_test, y_train, y_test, feature_names = data_processing(df)\n",
        "```"
      ],
      "metadata": {
        "id": "NpiCbrVy4SmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n",
        "#### Hyperparameter tuning\n",
        "With all the data cleaned and processed, it's time to begin training our model. The most effective way to train a model is by tuning hyperparameters through the use of cross validation. The `hyperopt` library uses a form of Bayesian optimization for parameter tuning that allows you to get the best parameters for a given model. Hyperparameter tuning with hyperopt has three features: space, objective, and fmin. Let's first look at the space in the code below:"
      ],
      "metadata": {
        "id": "NKfvWXry6SzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tQM-kKRDGVnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'learning_rate' : hp.choice('learning_rate', [0.01,0.1]),\n",
        "    'min_child_weight' : hp.choice('min_child_weight', np.arange(1,5,1, dtype=int)),\n",
        "    'max_depth' : hp.choice('max_depth', np.arange(3,12,3, dtype=int)),\n",
        "    'gamma': hp.choice('gamma', [i/10.0 for i in range(0,5)]),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.5, 1.0, 0.1)),\n",
        "    'n_estimators': hp.choice('n_estimators', [100,150]),\n",
        "    'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
        "    'reg_lambda' : hp.uniform('reg_lambda', 0,1)\n",
        "    }"
      ],
      "metadata": {
        "id": "TOGYtN6f8TPq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you've probably guessed, the space holds information concerning the hyperparameters that will be tuned in the model. I'm not going to go into detail on the different hyperparameters, so be sure to check out the xgboost documentation to learn more.\n",
        "\n",
        "The next feature is the objective function, which is defined below:"
      ],
      "metadata": {
        "id": "izwgcmKf9lNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=909)\n",
        "def objective(space):\n",
        "  xgb_clf = XGBClassifier(**space, seed=909, objective='binary:logistic', tree_method='gpu_hist', scale_pos_weight=1/.187)\n",
        "  score = cross_val_score(estimator= xgb_clf,\n",
        "                          X=X_train,\n",
        "                          y=y_train,\n",
        "                          cv=kfold,\n",
        "                          scoring='f1',\n",
        "                          n_jobs=-1).mean()\n",
        "\n",
        "  loss = - score\n",
        "\n",
        "  return {'loss' : loss, 'params' : space, 'status' : STATUS_OK}"
      ],
      "metadata": {
        "id": "f-jcDSYi925g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective function holds the definition for the model, and the evaluation metric. Using `StratifiedKFoldValidation`, the best objective function will be used to optimize our metric, in this case the F1 score. \n",
        "\n",
        "There are a couple items in the objective function that I want to point out. Within the definition of the XGBClassifier, I have two additional hyperparameters set. The first is the tree_method which is set for 'gpu_hist'. This allows for the use of a GPU for training and can help train the model faster. The second is the scale_pos_weight, which can be used in the case of imbalanced data. If we take a look at the target variable, about 80% of the target variables fall into the non-delayed class. This is a heavy imbalance and requires some adjustments to the model. A good rule of thumb is to take 1 / the ratio of your less reprented class. In this case, we're going to set that weight as 1/.187 to help with the imbalance.\n",
        "\n"
      ],
      "metadata": {
        "id": "-fnEyWGt98v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='DEP_DEL15', stat='probability')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "lQSfxuMoA9KG",
        "outputId": "b21a152a-611a-43ac-8a6c-d745cb3a492a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='DEP_DEL15', ylabel='Probability'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The third feature is the `fmin` function which takes the objective function and the space and begins that cross-validation process for picking those hyperparameters. Let's get that started now:"
      ],
      "metadata": {
        "id": "43hGjKFHBA3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 20, return_argmin=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnCWgWTv-yI0",
        "outputId": "7599c109-1854-4a07-bd6b-cf9c7eb09dca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|ââââââââââ| 20/20 [14:48<00:00, 44.45s/trial, best loss: -0.42560369413745747]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now take a look at the values for those hyperparameters"
      ],
      "metadata": {
        "id": "lOr0L_FzGFMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r88XZUFhFF0v",
        "outputId": "273e2546-3220-4613-9706-1f4f7481b899"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.6,\n",
              " 'gamma': 0.2,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 9,\n",
              " 'min_child_weight': 1,\n",
              " 'n_estimators': 150,\n",
              " 'reg_alpha': 65.0,\n",
              " 'reg_lambda': 0.1452277681223374}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model\n",
        "Now that the hyperparemeters are tuned, we can pass the best dictionary into the XGBClassifier to fit the model."
      ],
      "metadata": {
        "id": "_UJdCJMYGPiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(**best,objective='binary:logistic', tree_method='gpu_hist', scale_pos_weight=1/.187)\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "_-uIQotyGkQ1",
        "outputId": "0e3fba1a-d166-42c0-b470-0cee645fe00b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model\n",
        "Now that the model has been fit, let's look at how the model performs. I am going to define a function that takes the model and the data as an input and returns accuracy, ROC_AUC, and F1:"
      ],
      "metadata": {
        "id": "8TjwiyqoGqml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,x,y):\n",
        "  preds = model.predict(x)\n",
        "  proba = model.predict_proba(x)[:,1]\n",
        "  accuracy = round(accuracy_score(y, preds),3)\n",
        "  roc_auc = round(roc_auc_score(y, proba),3)\n",
        "  f1 = round(f1_score(y,preds),3)\n",
        "\n",
        "  print(f'Accuracy: {accuracy}')\n",
        "  print(f'ROC AUC: {roc_auc}')\n",
        "  print(f'F1: {f1}')"
      ],
      "metadata": {
        "id": "wR-E6uhTGm8s"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7jm5xUhG-b6",
        "outputId": "c6155f0a-e7a6-4cb6-f62f-87416c7cdcec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.626\n",
            "ROC AUC: 0.74\n",
            "F1: 0.425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r21xBGVHBPG",
        "outputId": "a5c24be2-31ff-453a-9805-02994021aedd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.632\n",
            "ROC AUC: 0.756\n",
            "F1: 0.436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "Unfortunately, this particular dataset is a bit more difficult to accuractely model with the significant imbalance in the data. We do the best that we can with the data that is provided. In the words of famous statistician George Box, \"all models are wrong, but some are useful\". I hope that this had increased your understanding of XGBoost and it's potential for training highly generalized models and large datasets in a quick amount of time."
      ],
      "metadata": {
        "id": "kRNqsPwpHPvR"
      }
    }
  ]
}